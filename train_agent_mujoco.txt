2023/01/13: Setting 1
running : OSPOESparseControl, ENIAC, PPOControl
parameters : 
    gamma == 0.99 (hopper, walker2d, halfcheetah)
    int_gamma == 0.99 (hopper, walker2d, halfcheetah)
    ent_coeff == 0.0 (hopper, walker2d, halfcheetah)

    * extra bonus set: adv = adv + 2 * bonus_adv (try later)
    * normal set: adv = adv + bonus_adv



(not current)
2023/01/14: Setting 2
running : OSPOESparseControl, ENIAC, PPOControl
env parameters :
    n_envs = 32
    n_steps = 64
parameters :
    gamma == 0.99 (walker2d, halfcheetah)
    gamma == 0.999 (hopper)
    int_gamma == 0.99 (hopper, walker2d, halfcheetah)
    ent_coeff == 0.001 (hopper, walker2d, halfcheetah)


2023/01/14: Setting 1*
running : OSPOESparseControl, ENIAC, PPOControl
parameters : 
    gamma == 0.99 (hopper, walker2d, halfcheetah)
    int_gamma == 0.99 (hopper, walker2d, halfcheetah)
    ent_coeff == 0.0 (hopper, walker2d, halfcheetah)

    The difference between this setting and the previous setting, is that 
    we normalize two adv term sperately
    * extra bonus set: adv = adv + 2 * bonus_adv (try later)
    * normal set: adv = adv + bonus_adv

2023/01/15: 
running : OSPOESparseControl, ENIAC, PPOControl
parameters: (Walker2d, Halfcheetah)
    gamma == 0.99
    int_gamma == 0.99
    ent_coeff == 0.001, clip_range == 0.1
    advatanges (int and ext) are normalized separately, total_adv = adv + 0.5 * int_adv
    n_envs = 8, random seeds are picked by run * 8 (so no two experiments share same seeds)

2023/01/15: (sparse)
64 envs 
batch_size = 32
n_epochs = 10
learning_rate = 1e-4
clip_range = 0.2
ent_coef = 0.001
gamma = 0.999
int_gamma = 0.99

halfcheetah : abs(afterpos) > 15. (worked)
hopper : (afterpos - init_pos[0]) > 1. (worked)
walker2d : (afterpos - init_pos[0]) > 0.2 (running)
humanoid : abs(afterpos) > 0.3 (running)
